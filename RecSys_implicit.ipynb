{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecSys: implicit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOS91BJGJGzaJb8YEIbXPhu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwordForShinobi/Retail-recommender-system/blob/main/RecSys_implicit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "CbArspHe00LX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN7d8RzPudoO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install implicit # if you get lucky, you\"ll be able to install it like this\n",
        "!sudo -H python3 -m pip install implicit --no-cache --force-reinstall --log ./implicit.txt # if you won't be so lucky\n",
        "# this precautions are for windows"
      ],
      "metadata": {
        "id": "TBbb_FravMWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation class"
      ],
      "metadata": {
        "id": "1Z3ui68F04L5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFUeJDLWZwyZ"
      },
      "outputs": [],
      "source": [
        "# This class prepares data before feeding them to model\n",
        "class PrepareData:\n",
        "  '''IMPORTANT! Use .read transactions() and/or .read_products() before, otherwise other methods will be unavaliable'''\n",
        "  def __init__(self):\n",
        "    self.trans_df = None\n",
        "    self.prods_df = None\n",
        "    self.purchases = None\n",
        "\n",
        "  def read_transactions(self, trans_dir=None): # чтение файлов transactions и products\n",
        "    '''Pass directory(string) of desired file you wish to create DataFrame from'''\n",
        "    if trans_dir is not None:\n",
        "      self.trans_df = pd.read_csv(trans_dir, sep=',')\n",
        "      return self.trans_df\n",
        "    else:\n",
        "      print('Please, input directory')\n",
        "\n",
        "  def read_products(self, prods_dir=None):\n",
        "    '''Pass directory(string) of desired file you wish to create DataFrame from'''\n",
        "    if prods_dir is not None:\n",
        "      self.prods_df = pd.read_csv(prods_dir, sep=',')\n",
        "      return self.prods_df\n",
        "    else:\n",
        "      print('Please, input directory')\n",
        "\n",
        "  def create_user_list(self): # уникальные user_id из transactions\n",
        "    if self.trans_df is not None:\n",
        "      self.user_list_trans = self.trans_df.user_id.unique().tolist()\n",
        "      return self.user_list_trans\n",
        "    else:\n",
        "      raise ValueError('Load data 1st! Read some dataframes!')\n",
        "\n",
        "  def save_user_list(self, directory):\n",
        "    '''type full directory, must be a string'''\n",
        "    if self.user_list_trans is None:\n",
        "        self.create_user_list()\n",
        "    np.save(directory, self.user_list_trans)\n",
        "    print(\"Saved successfully!\")\n",
        "\n",
        "  def read_user_list(self, directory): # чтение из файла списка уникальных юзеров\n",
        "    '''type full directory, must be a string'''\n",
        "    self.user_list_trans = np.load(directory+'.npy', allow_pickle=True)\n",
        "    return list(self.user_list_trans)\n",
        "\n",
        "  def trans_add_string(self, order_id, user_id, order_number, order_dow,\n",
        "                       order_hour_of_day, days_since_prior_order, product_id,\n",
        "                       add_to_cart_order, reordered): # + новая строка в транзакции\n",
        "    empty_row = pd.DataFrame(np.array([order_id, user_id, order_number, order_dow, order_hour_of_day,\n",
        "                              days_since_prior_order, product_id, add_to_cart_order, reordered]).reshape(1, len(self.trans_df.columns)),\n",
        "                             columns=list(self.trans_df.columns))\n",
        "    new_trans_df = self.trans_df.append(empty_row, ignore_index=True)\n",
        "    return new_trans_df\n",
        "\n",
        "  def prods_add_string(self, product_id, product_name, aisle_id, department_id,\n",
        "                       aisle, department): # + новая строка в продукты\n",
        "    empty_row = pd.DataFrame(np.array([product_id, product_name, aisle_id, department_id,\n",
        "                              aisle, department]).reshape(1, len(self.prods_df.columns)),\n",
        "                             columns=list(self.prods_df.columns))\n",
        "    new_prods_df = self.prods_df.append(empty_row, ignore_index=True)\n",
        "    return new_prods_df\n",
        "\n",
        "  def each_user_orders(self, users, products, number_of_orders): # сколько раз отдельный юзер покупал каждый продукт\n",
        "    '''all are strings:\n",
        "        users - name of columns with user ids,\n",
        "        products - name of columns with product ids,\n",
        "        number_of_orders - counts purchases of each product ever done by the user'''\n",
        "    self.users = users\n",
        "    self.products = products\n",
        "    self.number_of_orders = number_of_orders\n",
        "\n",
        "    self.purchases = self.trans_df.groupby([users, products])[number_of_orders].size().reset_index()\n",
        "    return self.purchases\n",
        "\n",
        "  def save_user_orders(self, directory): # сохранение посчитанных покупок каждого юзера\n",
        "    if self.purchases is not None:\n",
        "      self.purchases.to_csv(directory, index=False, sep=',', encoding='utf-8')\n",
        "      print(\"Saved successfully!\")\n",
        "    else:\n",
        "      raise ValueError('Nothing to save! Create dataframe 1st!')\n",
        "\n",
        "  def read_user_orders(self, directory): # загрузка посчитанных покупок каждого юзера (ранее сохраненных)\n",
        "    self.purchases = pd.read_csv(directory, sep=',')\n",
        "    return self.purchases\n",
        "  \n",
        "  def to_fit_coded(self):\n",
        "    if self.purchases is not None:\n",
        "      df = self.purchases\n",
        "      for i in [self.users, self.products, self.number_of_orders]:\n",
        "        df[i+'_coded'] = df[i]\n",
        "      for i in [self.users+'_coded', self.products+'_coded', self.number_of_orders+'_coded']:\n",
        "        df[i] = df[i].astype(\"category\")\n",
        "        df[i] = df[i].cat.codes\n",
        "      df.columns = ['user_id', 'product_id', 'number_of_orders',\n",
        "                    'user_id(coded)', 'product_id(coded)', 'number_of_orders(coded)']\n",
        "      return df\n",
        "    else:\n",
        "      raise ValueError('Use each_user_orders() method 1st')\n",
        "  \n",
        "  def to_fit_pure(self): # так ли нам нужно кодировать? Ведь потом придется РАСкодировтаь +)\n",
        "    if self.purchases is not None:\n",
        "      df = self.purchases\n",
        "      df.columns = ['user_id', 'product_id', 'number_of_orders']\n",
        "      return df\n",
        "    else:\n",
        "      raise ValueError('Use each_user_orders() method 1st')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = PrepareData()"
      ],
      "metadata": {
        "id": "4gwbzg4nwwpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs0El2cvBJD4"
      },
      "outputs": [],
      "source": [
        "data.read_transactions('directory') # to try out put here file from this repository: main/Data/transactions.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tq1n-3LA6TW"
      },
      "outputs": [],
      "source": [
        "# Creates dataframe with coded transactions of each user to work with\n",
        "to_fit = data.to_fit_coded()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model based on ALS"
      ],
      "metadata": {
        "id": "hwVxPH140-Xb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLjQPgjmu53-"
      },
      "outputs": [],
      "source": [
        "class ModelALS:\n",
        "  '''Model class based on ALS algorythm'''\n",
        "  def __init__(self, factors=None, iterations=None):\n",
        "    self.factors = factors\n",
        "    self.iterations = iterations\n",
        "\n",
        "    if self.factors is not None and self.iterations is not None:\n",
        "      self.model = ALS(self.factors, self.iterations)\n",
        "    else:\n",
        "      raise ValueError('Please set parameters when create class')\n",
        "\n",
        "  def prepare_matrix_to_fit(self, df=None):\n",
        "    self.df = df\n",
        "    if self.df is not None: # передаем сюда ЗАКОДИРОВАННЫЕ столбцы\n",
        "      row = np.array(self.df[self.df.columns[3]].values.tolist()) # users\n",
        "      col = np.array(self.df[self.df.columns[4]].values.tolist()) # products\n",
        "      data = np.array(self.df[self.df.columns[5]].values.tolist()) # how many purchased\n",
        "      self.matrix = csr((data, (row, col)), dtype=np.float32)\n",
        "      return self.matrix\n",
        "    else:\n",
        "      raise ValueError('Please pass dataframe to work with')\n",
        "  \n",
        "  def fit_model(self):\n",
        "    self.model.fit(self.matrix.T)\n",
        "\n",
        "  def predict_user(self, user, n, filter_already_liked_items=True):\n",
        "    '''user = particular user id(integer)\n",
        "        n = amount of items to predict(integer)'''\n",
        "    code_user = self.df[self.df[self.df.columns[0]] == user][self.df.columns[3]].unique()[0]\n",
        "    recommendations = [t[0] for t in self.model.recommend(code_user, self.matrix, n, filter_already_liked_items)]\n",
        "    recs = self.df[self.df[self.df.columns[4]].isin(recommendations)][self.df.columns[1]].unique().tolist()\n",
        "    return f'For user_id={user}, we recommend next items, ids: {recs}'\n",
        "\n",
        "  def predict_many(self, users, n, filter_already_liked_items=True):\n",
        "    '''users = users you wish to predict(list)\n",
        "        n = amount of items to predict for each user(integer)'''\n",
        "    self.users = users\n",
        "    self.preds_list = []\n",
        "    users_code = self.df[self.df[self.df.columns[0]].isin(users)][self.df.columns[3]].unique().tolist()\n",
        "    decode_df = self.df[[self.df.columns[4], self.df.columns[1]]].drop_duplicates() # создадим короткий дф для раскодировки. Ниже эксперементально проверенно:\n",
        "    # он очень сильно ускоряет процесс\n",
        "    for i in users_code:\n",
        "      recommendations = [t[0] for t in self.model.recommend(i, self.matrix, n, filter_already_liked_items, recalculate_user=True)]\n",
        "      self.preds_list.append(recommendations)\n",
        "    return self.preds_list\n",
        "\n",
        "  def decode_predictions(self, preds_list = None):\n",
        "    self.preds_list = preds_list\n",
        "    if self.preds_list is not None:\n",
        "      decode_df = self.df[[self.df.columns[4], self.df.columns[1]]].drop_duplicates() # создадим короткий дф для раскодировки. Ниже экспериментально проверенно\n",
        "      decode = []\n",
        "\n",
        "      for i in self.preds_list:\n",
        "        decoded_string = decode_df[decode_df['product_id(coded)'].isin(i)]['product_id'].unique().tolist()\n",
        "        decode.append(decoded_string)\n",
        "      # Сразу уберем пунктуацию для сохр-я и отправки на кэггл:\n",
        "      characters_to_remove = '[],'\n",
        "      clear_items_list = []\n",
        "\n",
        "      for string in decode:\n",
        "        for i in characters_to_remove:\n",
        "          string = str(string).replace(i, '')\n",
        "        clear_items_list.append(string)\n",
        "  \n",
        "      answer = pd.DataFrame(np.array(self.users).reshape(len(self.users), 1), columns=['user_id'])\n",
        "      answer['product_id'] = clear_items_list\n",
        "      return answer\n",
        "    else:\n",
        "      raise ValueError('Use predict_many() method 1st then pass predictions')\n",
        "\n",
        "  def save_model(self, path=None):\n",
        "    if path is not None:\n",
        "      with open(path, 'wb') as directory:\n",
        "        pickle.dump(self.model, directory)\n",
        "    else:\n",
        "      raise ValueError('Please input desirable path/filename to save to')\n",
        "    \n",
        "  def load_model(self, path=None):\n",
        "    if path is not None:\n",
        "      with open(path, 'rb') as model_probe:\n",
        "        self.model = pickle.load(model_probe)\n",
        "    else:\n",
        "      raise ValueError('Please input desirable path/filename to load from')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1vHptAojLYE"
      },
      "outputs": [],
      "source": [
        "# factors=30, iterations=8\n",
        "model = ModelALS(30, 8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sparse user_item_weights matrix\n",
        "matrix = model.prepare_matrix_to_fit(to_fit)"
      ],
      "metadata": {
        "id": "uEMiNw-quqYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_model()"
      ],
      "metadata": {
        "id": "d2W49YpcuuLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVAJkeG256Qv"
      },
      "outputs": [],
      "source": [
        "model.save_model('anywhere')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aviY4f46lhi"
      },
      "outputs": [],
      "source": [
        "model.load_model('anywhere')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CfjBvwJdLNT"
      },
      "outputs": [],
      "source": [
        "# Predict top k (top 10 in our case) for user 2653\n",
        "model.predict_user(2653, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVippZmNmQLM"
      },
      "outputs": [],
      "source": [
        "# Predict top 10 for list of users\n",
        "model.predict_many(to_fit['user_id'].unique().tolist(), 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding kNN method"
      ],
      "metadata": {
        "id": "zfYKtCIW1DUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShAytFd9oeCv"
      },
      "outputs": [],
      "source": [
        "class kNN(ModelALS):\n",
        "  def __init__(self, k=50):\n",
        "    self.k=k\n",
        "    self.model = CR(self.k)\n",
        "\n",
        "  def prepare_matrix_to_fit(self, df=None):\n",
        "    self.df = df\n",
        "    if self.df is not None:\n",
        "      row = np.array(self.df[self.df.columns[3]].values.tolist()) # users\n",
        "      col = np.array(self.df[self.df.columns[4]].values.tolist()) # products\n",
        "      data = np.array(self.df[self.df.columns[5]].values.tolist()) # how many purchased\n",
        "      self.matrix = csr((data, (row, col)), dtype=np.double) # ради этого пришлось писать функцию полностью\n",
        "      return self.matrix\n",
        "    else:\n",
        "      raise ValueError('Please pass dataframe to work with')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h--qnmPFpLXu"
      },
      "outputs": [],
      "source": [
        "# Create for 10 neighbours\n",
        "model_knn = kNN(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPzwBoX8pQnA"
      },
      "outputs": [],
      "source": [
        "matrix_knn = model_knn.prepare_matrix_to_fit(to_fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5FCDqpRp86F"
      },
      "outputs": [],
      "source": [
        "model_knn.fit_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2KKzq9ZtDQ0"
      },
      "outputs": [],
      "source": [
        "# predicts for list of users\n",
        "model_knn.predict_many(to_fit['user_id'].unique().tolist(), 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You may load, save and predict for single user as well"
      ],
      "metadata": {
        "id": "Ip1FwBfP0oQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}